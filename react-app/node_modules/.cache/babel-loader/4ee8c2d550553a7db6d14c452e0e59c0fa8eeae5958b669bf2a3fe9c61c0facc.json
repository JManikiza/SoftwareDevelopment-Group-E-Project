{"ast":null,"code":"'use strict';\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js');\nvar prefixSize = require('../util/prefix-size.js');\nvar subtokenize = require('../util/subtokenize.js');\nvar factorySpace = require('./factory-space.js');\n\n// No name because it must not be turned off.\nvar content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent,\n  interruptible: true,\n  lazy: true\n};\nvar continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n}; // Content is transparent: it’s parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\nfunction tokenizeContent(effects, ok) {\n  var previous;\n  return start;\n  function start(code) {\n    effects.enter('content');\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    });\n    return data(code);\n  }\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n    effects.consume(code);\n    return data;\n  }\n  function contentEnd(code) {\n    effects.exit('chunkContent');\n    effects.exit('content');\n    return ok(code);\n  }\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit('chunkContent');\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    });\n    return data;\n  }\n}\nfunction tokenizeContinuation(effects, ok, nok) {\n  var self = this;\n  return startLookahead;\n  function startLookahead(code) {\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, prefixed, 'linePrefix');\n  }\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n    if (self.parser.constructs.disable.null.indexOf('codeIndented') > -1 || prefixSize(self.events, 'linePrefix') < 4) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n    }\n    return ok(code);\n  }\n}\nmodule.exports = content;","map":{"version":3,"names":["markdownLineEnding","require","prefixSize","subtokenize","factorySpace","content","tokenize","tokenizeContent","resolve","resolveContent","interruptible","lazy","continuationConstruct","tokenizeContinuation","partial","events","effects","ok","previous","start","code","enter","contentType","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","prefixed","parser","constructs","disable","null","indexOf","interrupt","flow","module","exports"],"sources":["C:/Users/JMani/Documents/GitHub/SoftwareDevelopment-Group-E-Project/react-app/node_modules/micromark/dist/tokenize/content.js"],"sourcesContent":["'use strict'\n\nvar markdownLineEnding = require('../character/markdown-line-ending.js')\nvar prefixSize = require('../util/prefix-size.js')\nvar subtokenize = require('../util/subtokenize.js')\nvar factorySpace = require('./factory-space.js')\n\n// No name because it must not be turned off.\nvar content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent,\n  interruptible: true,\n  lazy: true\n}\nvar continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n} // Content is transparent: it’s parsed right now. That way, definitions are also\n// parsed right now: before text in paragraphs (specifically, media) are parsed.\n\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\nfunction tokenizeContent(effects, ok) {\n  var previous\n  return start\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return data(code)\n  }\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous = previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous: previous\n    })\n    return data\n  }\n}\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  var self = this\n  return startLookahead\n\n  function startLookahead(code) {\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    if (\n      self.parser.constructs.disable.null.indexOf('codeIndented') > -1 ||\n      prefixSize(self.events, 'linePrefix') < 4\n    ) {\n      return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n    }\n\n    return ok(code)\n  }\n}\n\nmodule.exports = content\n"],"mappings":"AAAA,YAAY;;AAEZ,IAAIA,kBAAkB,GAAGC,OAAO,CAAC,sCAAsC,CAAC;AACxE,IAAIC,UAAU,GAAGD,OAAO,CAAC,wBAAwB,CAAC;AAClD,IAAIE,WAAW,GAAGF,OAAO,CAAC,wBAAwB,CAAC;AACnD,IAAIG,YAAY,GAAGH,OAAO,CAAC,oBAAoB,CAAC;;AAEhD;AACA,IAAII,OAAO,GAAG;EACZC,QAAQ,EAAEC,eAAe;EACzBC,OAAO,EAAEC,cAAc;EACvBC,aAAa,EAAE,IAAI;EACnBC,IAAI,EAAE;AACR,CAAC;AACD,IAAIC,qBAAqB,GAAG;EAC1BN,QAAQ,EAAEO,oBAAoB;EAC9BC,OAAO,EAAE;AACX,CAAC,EAAC;AACF;;AAEA,SAASL,cAAcA,CAACM,MAAM,EAAE;EAC9BZ,WAAW,CAACY,MAAM,CAAC;EACnB,OAAOA,MAAM;AACf;AAEA,SAASR,eAAeA,CAACS,OAAO,EAAEC,EAAE,EAAE;EACpC,IAAIC,QAAQ;EACZ,OAAOC,KAAK;EAEZ,SAASA,KAAKA,CAACC,IAAI,EAAE;IACnBJ,OAAO,CAACK,KAAK,CAAC,SAAS,CAAC;IACxBH,QAAQ,GAAGF,OAAO,CAACK,KAAK,CAAC,cAAc,EAAE;MACvCC,WAAW,EAAE;IACf,CAAC,CAAC;IACF,OAAOC,IAAI,CAACH,IAAI,CAAC;EACnB;EAEA,SAASG,IAAIA,CAACH,IAAI,EAAE;IAClB,IAAIA,IAAI,KAAK,IAAI,EAAE;MACjB,OAAOI,UAAU,CAACJ,IAAI,CAAC;IACzB;IAEA,IAAIpB,kBAAkB,CAACoB,IAAI,CAAC,EAAE;MAC5B,OAAOJ,OAAO,CAACS,KAAK,CAClBb,qBAAqB,EACrBc,eAAe,EACfF,UAAU,CACX,CAACJ,IAAI,CAAC;IACT,CAAC,CAAC;;IAEFJ,OAAO,CAACW,OAAO,CAACP,IAAI,CAAC;IACrB,OAAOG,IAAI;EACb;EAEA,SAASC,UAAUA,CAACJ,IAAI,EAAE;IACxBJ,OAAO,CAACY,IAAI,CAAC,cAAc,CAAC;IAC5BZ,OAAO,CAACY,IAAI,CAAC,SAAS,CAAC;IACvB,OAAOX,EAAE,CAACG,IAAI,CAAC;EACjB;EAEA,SAASM,eAAeA,CAACN,IAAI,EAAE;IAC7BJ,OAAO,CAACW,OAAO,CAACP,IAAI,CAAC;IACrBJ,OAAO,CAACY,IAAI,CAAC,cAAc,CAAC;IAC5BV,QAAQ,GAAGA,QAAQ,CAACW,IAAI,GAAGb,OAAO,CAACK,KAAK,CAAC,cAAc,EAAE;MACvDC,WAAW,EAAE,SAAS;MACtBJ,QAAQ,EAAEA;IACZ,CAAC,CAAC;IACF,OAAOK,IAAI;EACb;AACF;AAEA,SAASV,oBAAoBA,CAACG,OAAO,EAAEC,EAAE,EAAEa,GAAG,EAAE;EAC9C,IAAIC,IAAI,GAAG,IAAI;EACf,OAAOC,cAAc;EAErB,SAASA,cAAcA,CAACZ,IAAI,EAAE;IAC5BJ,OAAO,CAACK,KAAK,CAAC,YAAY,CAAC;IAC3BL,OAAO,CAACW,OAAO,CAACP,IAAI,CAAC;IACrBJ,OAAO,CAACY,IAAI,CAAC,YAAY,CAAC;IAC1B,OAAOxB,YAAY,CAACY,OAAO,EAAEiB,QAAQ,EAAE,YAAY,CAAC;EACtD;EAEA,SAASA,QAAQA,CAACb,IAAI,EAAE;IACtB,IAAIA,IAAI,KAAK,IAAI,IAAIpB,kBAAkB,CAACoB,IAAI,CAAC,EAAE;MAC7C,OAAOU,GAAG,CAACV,IAAI,CAAC;IAClB;IAEA,IACEW,IAAI,CAACG,MAAM,CAACC,UAAU,CAACC,OAAO,CAACC,IAAI,CAACC,OAAO,CAAC,cAAc,CAAC,GAAG,CAAC,CAAC,IAChEpC,UAAU,CAAC6B,IAAI,CAAChB,MAAM,EAAE,YAAY,CAAC,GAAG,CAAC,EACzC;MACA,OAAOC,OAAO,CAACuB,SAAS,CAACR,IAAI,CAACG,MAAM,CAACC,UAAU,CAACK,IAAI,EAAEV,GAAG,EAAEb,EAAE,CAAC,CAACG,IAAI,CAAC;IACtE;IAEA,OAAOH,EAAE,CAACG,IAAI,CAAC;EACjB;AACF;AAEAqB,MAAM,CAACC,OAAO,GAAGrC,OAAO"},"metadata":{},"sourceType":"script","externalDependencies":[]}